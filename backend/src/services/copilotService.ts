import OpenAI from 'openai';
import { Octokit } from '@octokit/rest';
import type { AgentConfig } from '../models/agent';

// ============================================================
// GiLo AI ‚Äì GitHub Copilot Integration Service
// Uses the official GitHub Models endpoint (compatible OpenAI SDK)
// and the Octokit REST SDK for repository operations.
// ============================================================

export interface CopilotMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface CopilotChatRequest {
  messages: CopilotMessage[];
  model?: string;
  temperature?: number;
  maxTokens?: number;
  stream?: boolean;
  /** Detected UI language from the frontend (i18n) */
  uiLanguage?: string;
  /** Optional project context injected as system prompt */
  projectContext?: {
    projectId: string;
    techStack?: string[];
    files?: string[];
  };
}

export interface CopilotChatResponse {
  id: string;
  content: string;
  model: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  finishReason: string;
}

export interface CopilotStreamChunk {
  type: 'content' | 'done' | 'error';
  content?: string;
  finishReason?: string;
  error?: string;
}

// ============================================================
// Copilot Service
// ============================================================

export class CopilotService {
  private openai: OpenAI;
  private octokit: Octokit;
  private defaultModel: string;

  private initialized = false;

  constructor() {
    // Defer actual init ‚Äì env vars may not be loaded yet at import time
    this.openai = null as any;
    this.octokit = null as any;
    this.defaultModel = 'openai/gpt-4.1-nano';
  }

  /** Lazy-initialize clients so env vars from dotenv are available */
  private ensureInit() {
    if (this.initialized) return;
    this.initialized = true;

    const githubToken = process.env.GITHUB_TOKEN;
    if (!githubToken) {
      console.warn('‚ö†Ô∏è  GITHUB_TOKEN not set ‚Äì Copilot features will be unavailable');
    }

    this.openai = new OpenAI({
      baseURL: process.env.COPILOT_API_URL || 'https://models.github.ai/inference',
      apiKey: githubToken || 'dummy',
    });

    this.octokit = new Octokit({ auth: githubToken });
    this.defaultModel = process.env.COPILOT_MODEL || 'openai/gpt-4.1-nano';
  }

  // ----------------------------------------------------------
  // Expose client info for direct route usage
  // ----------------------------------------------------------
  getClientInfo(projectContext?: CopilotChatRequest['projectContext'], agentConfig?: import('../models/agent').AgentConfig, uiLanguage?: string, messages?: CopilotMessage[], enrichedContext?: Record<string, any>): {
    client: OpenAI;
    systemPrompt: string;
    defaultModel: string;
  } {
    this.ensureInit();
    return {
      client: this.openai,
      systemPrompt: this.buildSystemPrompt(projectContext, agentConfig, uiLanguage, messages, enrichedContext),
      defaultModel: this.defaultModel,
    };
  }

  // ----------------------------------------------------------
  // Get an OpenAI client for a specific agent.
  // If the agent has BYO LLM configured, creates a new client
  // with the user's key & URL.  Otherwise returns our default.
  // ----------------------------------------------------------
  getClientForAgent(agentConfig: AgentConfig): {
    client: OpenAI;
    model: string;
    isByo: boolean;
  } {
    if (agentConfig.customLlmKey?.trim()) {
      const client = new OpenAI({
        apiKey: agentConfig.customLlmKey.trim(),
        baseURL: agentConfig.customLlmUrl?.trim() || 'https://api.openai.com/v1',
      });
      return {
        client,
        model: agentConfig.customLlmModel?.trim() || 'gpt-4o-mini',
        isByo: true,
      };
    }

    this.ensureInit();
    return {
      client: this.openai,
      model: agentConfig.model || this.defaultModel,
      isByo: false,
    };
  }

  // ----------------------------------------------------------
  // Detect user language from messages
  // ----------------------------------------------------------
  private detectLanguage(messages: CopilotMessage[], uiLanguage?: string): string {
    // Priority 1: explicit UI language from frontend
    if (uiLanguage && ['fr', 'en', 'es', 'de', 'pt', 'it', 'ar', 'zh', 'ja', 'ko'].includes(uiLanguage)) {
      return uiLanguage;
    }
    // Priority 2: detect from last user message
    const lastUserMsg = [...messages].reverse().find(m => m.role === 'user');
    if (lastUserMsg?.content) {
      const text = lastUserMsg.content.toLowerCase();
      // Simple heuristic patterns for language detection
      const patterns: Record<string, RegExp[]> = {
        fr: [/\b(bonjour|salut|merci|comment|je|nous|vous|pour|avec|dans|les|des|est|une|mon|que|cr√©er|ajouter|configurer|outils)\b/i],
        en: [/\b(hello|hi|thanks|please|how|the|and|for|with|create|add|configure|tools|help|want|need|build)\b/i],
        es: [/\b(hola|gracias|por favor|c√≥mo|crear|a√±adir|configurar|herramientas|ayuda|quiero|necesito)\b/i],
        de: [/\b(hallo|danke|bitte|wie|erstellen|hinzuf√ºgen|konfigurieren|werkzeuge|hilfe|m√∂chte|brauche)\b/i],
        pt: [/\b(ol√°|obrigado|por favor|como|criar|adicionar|configurar|ferramentas|ajuda|quero|preciso)\b/i],
        it: [/\b(ciao|grazie|per favore|come|creare|aggiungere|configurare|strumenti|aiuto|voglio|ho bisogno)\b/i],
        ar: [/[\u0600-\u06FF]/],
        zh: [/[\u4e00-\u9fff]/],
        ja: [/[\u3040-\u30ff\u31f0-\u31ff]/],
        ko: [/[\uac00-\ud7af]/],
      };
      for (const [lang, regexes] of Object.entries(patterns)) {
        if (regexes.some(r => r.test(text))) return lang;
      }
    }
    return 'fr'; // default
  }

  // ----------------------------------------------------------
  // Build the GiLo AI system prompt
  // ----------------------------------------------------------
  private buildSystemPrompt(projectContext?: CopilotChatRequest['projectContext'], agentConfig?: import('../models/agent').AgentConfig, uiLanguage?: string, messages?: CopilotMessage[], enrichedContext?: Record<string, any>): string {
    const detectedLang = this.detectLanguage(messages || [], uiLanguage);

    const langInstructions: Record<string, string> = {
      fr: 'R√©ponds TOUJOURS en fran√ßais.',
      en: 'ALWAYS respond in English.',
      es: 'Responde SIEMPRE en espa√±ol.',
      de: 'Antworte IMMER auf Deutsch.',
      pt: 'Responda SEMPRE em portugu√™s.',
      it: 'Rispondi SEMPRE in italiano.',
      ar: 'ÿ£ÿ¨ÿ® ÿØÿßÿ¶ŸÖÿßŸã ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©.',
      zh: 'ÂßãÁªàÁî®‰∏≠ÊñáÂõûÁ≠î„ÄÇ',
      ja: 'Â∏∏„Å´Êó•Êú¨Ë™û„ÅßÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ',
      ko: 'Ìï≠ÏÉÅ ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.',
    };

    const langInstruction = langInstructions[detectedLang] || langInstructions['fr'];

    let system = `Tu es GiLo AI, un assistant expert Full-Stack End-to-End Agent Builder, int√©gr√© dans la plateforme GiLo AI.
${langInstruction}
D√©tecte automatiquement la langue de l'utilisateur √† partir de ses messages et r√©ponds dans CETTE M√äME langue.

=== CAPACIT√âS FULL-STACK END-TO-END ===
Tu es capable de guider l'utilisateur √† travers TOUTE la cha√Æne de cr√©ation d'un agent IA :

1. **Conception** : D√©finir le r√¥le, la personnalit√©, le ton et le public cible
2. **Configuration du mod√®le** : Choix du LLM (GPT-4.1-nano, GPT-4.1-mini, BYO LLM), temp√©rature, max tokens
3. **System Prompt** : G√©n√©ration d'un prompt optimis√© et structur√© (100-300 mots)
4. **Outils & Int√©grations** : Configuration d'outils builtin, HTTP actions, MCP servers
5. **Base de connaissances** : Conseils pour l'upload de documents, scraping d'URLs
6. **API & Endpoints** : G√©n√©ration de tableaux pour configurer les endpoints et cl√©s API
7. **S√©curit√©** : Gestion s√©curis√©e des credentials (chiffrement AES-256-GCM)
8. **D√©ploiement** : Widget embed, API REST, sous-domaine personnalis√©
9. **Monitoring** : Analytics, logs, alertes
10. **Publication** : Publication dans le Store GiLo

=== G√âN√âRATION DE TABLEAUX API/ENDPOINTS ===
Quand l'utilisateur veut configurer des endpoints ou des cl√©s API, g√©n√®re un tableau Markdown structur√© :

| Nom | Type | Endpoint/URL | M√©thode | Auth Type | Cl√© API | Statut |
|-----|------|-------------|---------|-----------|---------|--------|
| Mon API | REST | https://api.example.com/v1 | POST | Bearer | ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè | ‚úÖ Actif |

Puis propose d'appliquer cette configuration automatiquement via le bloc <!--GILO_APPLY_CONFIG:...-->.

Quand tu g√©n√®res du code ou des configurations, entoure-les de blocs \`\`\` avec le langage appropri√©.
Sois concis et direct dans tes r√©ponses.
Les cl√©s API et secrets doivent TOUJOURS √™tre masqu√©s dans les r√©ponses visibles (utilise ‚óè‚óè‚óè‚óè‚óè ou ***).`;

    if (projectContext) {
      system += `\n\nContexte de l'agent en cours de cr√©ation:`;
      system += `\n- ID: ${projectContext.projectId}`;
      if (projectContext.techStack?.length) {
        system += `\n- Outils connect√©s: ${projectContext.techStack.join(', ')}`;
      }
      if (projectContext.files?.length) {
        system += `\n- Fichiers de configuration: ${projectContext.files.join(', ')}`;
      }
    }

    // Check if the agent is new/unconfigured and enable guided creation mode
    const isNewAgent = agentConfig && (
      agentConfig.systemPrompt === 'Tu es un assistant IA utile et concis. R√©ponds toujours de mani√®re professionnelle.' ||
      !agentConfig.systemPrompt?.trim()
    );

    if (isNewAgent) {
      system += `

=== MODE CR√âATION GUID√âE ===
L'utilisateur vient de cr√©er un nouvel agent qui n'est pas encore configur√©.
Tu dois le guider de mani√®re conversationnelle pour configurer son agent.

COMPORTEMENT :
1. Commence par accueillir l'utilisateur et lui demander de d√©crire √† quoi servira son agent (quel r√¥le, quel public cible, quel ton).
2. Pose des questions de suivi si n√©cessaire (2-3 questions max, pas plus).
3. Quand tu as assez d'informations, applique la configuration automatiquement.

QUAND TU G√âN√àRES LA CONFIGURATION :
- Tu DOIS inclure un bloc cach√© dans ta r√©ponse, TOUT √Ä LA FIN du message :
<!--GILO_APPLY_CONFIG:{"systemPrompt":"...", "temperature": 0.7, "maxTokens": 2048, "welcomeMessage": "...", "tools": [...]}-->
- Ce bloc est INVISIBLE pour l'utilisateur et sera automatiquement d√©tect√© et appliqu√©.

‚ö†Ô∏è R√àGLE ABSOLUE : Ne JAMAIS afficher le JSON de configuration dans ta r√©ponse visible.
Ne montre JAMAIS le contenu brut du bloc GILO_APPLY_CONFIG √† l'utilisateur.
Ne mets JAMAIS de bloc de code JSON contenant systemPrompt, temperature, tools, etc.
D√©cris simplement en langage naturel ce que tu as configur√© (ex: "J'ai configur√© votre agent avec un ton professionnel, en anglais...").
Le bloc <!--GILO_APPLY_CONFIG:...--> doit √™tre le DERNIER √©l√©ment de ta r√©ponse, apr√®s tout le texte visible.

OUTILS DISPONIBLES (inclure seulement les pertinents) :
- {"id":"builtin_get_current_time","name":"get_current_time","type":"builtin","enabled":true,"config":{"builtinId":"get_current_time"}} ‚Äî heure actuelle
- {"id":"builtin_calculator","name":"calculator","type":"builtin","enabled":true,"config":{"builtinId":"calculator"}} ‚Äî calculs math
- {"id":"builtin_http_get","name":"http_get","type":"builtin","enabled":true,"config":{"builtinId":"http_get"}} ‚Äî requ√™tes HTTP GET
- {"id":"builtin_http_post","name":"http_post","type":"builtin","enabled":true,"config":{"builtinId":"http_post"}} ‚Äî requ√™tes HTTP POST
- {"id":"builtin_json_extract","name":"json_extract","type":"builtin","enabled":true,"config":{"builtinId":"json_extract"}} ‚Äî extraction JSON
- {"id":"builtin_send_email","name":"send_email","type":"builtin","enabled":true,"config":{"builtinId":"send_email"}} ‚Äî envoi d'emails
- {"id":"builtin_webhook_trigger","name":"webhook_trigger","type":"builtin","enabled":true,"config":{"builtinId":"webhook_trigger"}} ‚Äî d√©clenchement webhooks

R√àGLES pour le systemPrompt g√©n√©r√© :
- 100 √† 300 mots, avec des instructions num√©rot√©es
- Adapt√© au ton et au contexte d√©crits par l'utilisateur
- DANS LA LANGUE d√©tect√©e de l'utilisateur

R√àGLES pour le welcomeMessage :
- Court (1-2 phrases), accueillant, en rapport avec le r√¥le de l'agent
- DANS LA LANGUE d√©tect√©e de l'utilisateur

=== AJOUT D'OUTILS VIA CONVERSATION ===
Quand l'utilisateur demande d'ajouter des outils ou des API :
1. Demande quels outils sp√©cifiques il veut (type, URL, auth)
2. G√©n√®re un TABLEAU r√©capitulatif en Markdown :

| # | Nom de l'outil | Type | Endpoint | M√©thode | Auth | Description |
|---|---------------|------|----------|---------|------|-------------|
| 1 | get_weather | HTTP | https://api.weather.com/v1 | GET | API Key | M√©t√©o en temps r√©el |
| 2 | send_notification | HTTP | https://api.notify.io/send | POST | Bearer | Envoi de notifications |

3. Demande confirmation √† l'utilisateur
4. Applique via <!--GILO_APPLY_CONFIG:{"tools":[...]}-->

=== CONFIGURATION DE CREDENTIALS (S√âCURIS√â) ===
Quand l'utilisateur veut configurer ses cl√©s API ou secrets :
1. G√©n√®re un tableau pour qu'il sache quelles infos fournir :

| Service | Champ | Valeur | S√©curis√© |
|---------|-------|--------|----------|
| OpenAI | API Key | sk-‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè | üîí Chiffr√© AES-256 |
| Stripe | Secret Key | sk_‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè | üîí Chiffr√© AES-256 |

2. Explique que les credentials sont stock√©s avec chiffrement AES-256-GCM
3. JAMAIS afficher les cl√©s en clair ‚Äî toujours masquer avec ‚óè‚óè‚óè‚óè‚óè ou ***
4. Utilise <!--GILO_SAVE_CREDENTIALS:{"credentials":[{"service":"...","key":"...","value":"MASKED"}]}--> pour signaler la sauvegarde

FORMAT DE R√âPONSE quand tu appliques la config :
1. D'abord, un r√©sum√© en langage naturel : "‚úÖ J'ai configur√© votre agent ! Voici ce que j'ai mis en place :"
2. Liste √† puces des choix faits (r√¥le, ton, langue, outils activ√©s) ‚Äî en texte simple, PAS de JSON
3. Si des outils/API sont configur√©s, un TABLEAU r√©capitulatif
4. Ensuite, propose les prochaines √©tapes :
   - Tester dans le Playground (ic√¥ne üëÅÔ∏è)
   - Ajuster la configuration (ic√¥ne ‚öôÔ∏è)
   - Ajouter des outils/API (ic√¥ne üîß)
   - Configurer la base de connaissances (ic√¥ne üìö)
   - D√©ployer (ic√¥ne üöÄ)
5. TOUT √Ä LA FIN, le bloc cach√© <!--GILO_APPLY_CONFIG:...-->

EXEMPLE DE BONNE R√âPONSE :
"‚úÖ Votre agent est configur√© ! Voici ce que j'ai mis en place :\n- **R√¥le** : Assistant support client\n- **Ton** : Professionnel\n- **Langue** : Anglais\n- **Outils** : Heure actuelle, Calculatrice\n- **Message d'accueil** : Hello! How can I help you today?\n\nVous pouvez maintenant le tester dans le Playground üëÅÔ∏è"
(suivi du bloc <!--GILO_APPLY_CONFIG:...--> invisible)

EXEMPLE DE MAUVAISE R√âPONSE (√Ä NE JAMAIS FAIRE) :
Afficher un bloc de code JSON avec systemPrompt, temperature, tools, etc.

=== FIN MODE CR√âATION GUID√âE ===`;
    } else if (agentConfig) {
      system += `\n\nConfiguration actuelle de l'agent:`;
      system += `\n- Mod√®le: ${agentConfig.model}`;
      system += `\n- Temp√©rature: ${agentConfig.temperature}`;
      system += `\n- System Prompt: ${agentConfig.systemPrompt?.substring(0, 200)}...`;
      system += `\n- Outils activ√©s: ${agentConfig.tools?.filter(t => t.enabled).map(t => `${t.name} (${t.type})`).join(', ') || 'aucun'}`;
      system += `\n- Outils d√©sactiv√©s: ${agentConfig.tools?.filter(t => !t.enabled).map(t => t.name).join(', ') || 'aucun'}`;

      // Enriched context
      if (enrichedContext) {
        if (enrichedContext.agentMeta) {
          const meta = enrichedContext.agentMeta;
          system += `\n- Nom de l'agent: ${meta.name || 'Non d√©fini'}`;
          system += `\n- Statut: ${meta.status || 'draft'}`;
          system += `\n- Conversations totales: ${meta.totalConversations || 0}`;
          system += `\n- Messages totaux: ${meta.totalMessages || 0}`;
          if (meta.deployedAt) system += `\n- D√©ploy√© le: ${new Date(meta.deployedAt).toLocaleDateString()}`;
        }
        if (enrichedContext.knowledgeStats) {
          const kb = enrichedContext.knowledgeStats;
          system += `\n- Base de connaissances: ${kb.documents} documents, ${kb.chunks} chunks, ${kb.totalTokens} tokens`;
        } else {
          system += `\n- Base de connaissances: vide (aucun document)`;
        }
        if (enrichedContext.credentialsCount !== undefined) {
          system += `\n- Credentials stock√©s: ${enrichedContext.credentialsCount}`;
        }
        if (enrichedContext.configScore !== undefined) {
          system += `\n- Score de compl√©tion config: ${enrichedContext.configScore}%`;
        }
      }

      system += `\n\n=== COMMANDES SLASH ===
L'utilisateur peut utiliser des commandes slash. Si tu d√©tectes une commande slash dans le message, ex√©cute-la :

/review ‚Äî Analyse la configuration actuelle de l'agent et sugg√®re des am√©liorations concr√®tes.
  Examine : system prompt (qualit√©, longueur, structure), outils configur√©s, temp√©rature, mod√®le, base de connaissances.
  Donne un score de qualit√© /10 et des suggestions prioritaires.

/optimize ‚Äî R√©√©cris et optimise le system prompt actuel pour de meilleures performances.
  Garde le m√™me r√¥le mais am√©liore la structure, les instructions et la clart√©.
  Applique automatiquement via <!--GILO_APPLY_CONFIG:...-->

/suggest-tools ‚Äî Analyse le r√¥le de l'agent et sugg√®re des outils pertinents √† ajouter.
  Pr√©sente dans un TABLEAU avec nom, type, description et utilit√©.

/status ‚Äî Affiche un r√©sum√© complet de l'√©tat de l'agent :
  Config, outils, base de connaissances, d√©ploiement, analytics.
  Montre un score de compl√©tion et les prochaines √©tapes recommand√©es.

/help ‚Äî Liste toutes les commandes disponibles avec leurs descriptions.

=== PROACTIVIT√â ===
Apr√®s chaque modification de config appliqu√©e, sugg√®re TOUJOURS les prochaines √©tapes pertinentes.
Analyse le score de compl√©tion et recommande les actions manquantes.
Si l'agent n'a pas de base de connaissances, sugg√®re d'en ajouter une.
Si l'agent n'a pas d'outils, sugg√®re les plus pertinents pour son r√¥le.
Si l'agent n'est pas d√©ploy√©, rappelle de le d√©ployer quand il est pr√™t.

=== MODIFICATIONS DE CONFIG ===
Si l'utilisateur demande des modifications, tu peux :
1. Modifier les param√®tres (mod√®le, temp√©rature, prompt, outils)
2. Ajouter/supprimer des outils avec un TABLEAU r√©capitulatif
3. Configurer des endpoints API avec un TABLEAU structur√© :

| Outil | Type | URL | M√©thode | Auth |
|-------|------|-----|---------|------|
| ... | HTTP | ... | POST | Bearer |

4. G√©n√®re le bloc cach√© pour appliquer :
<!--GILO_APPLY_CONFIG:{"systemPrompt":"...", "tools":[...], ...}-->

=== CREDENTIALS S√âCURIS√âS ===
Si l'utilisateur veut sauvegarder des cl√©s API :
- G√©n√®re un tableau montrant les champs n√©cessaires
- Signale que le stockage est chiffr√© AES-256-GCM
- NE JAMAIS afficher les cl√©s en clair
- Utilise <!--GILO_SAVE_CREDENTIALS:{"credentials":[...]}-->`;
    }

    return system;
  }

  // ----------------------------------------------------------
  // Non-streaming chat completion
  // ----------------------------------------------------------
  async chat(request: CopilotChatRequest): Promise<CopilotChatResponse> {
    this.ensureInit();

    const messages: OpenAI.ChatCompletionMessageParam[] = [
      { role: 'system', content: this.buildSystemPrompt(request.projectContext, undefined, request.uiLanguage, request.messages) },
      ...request.messages.map((m) => ({
        role: m.role as 'system' | 'user' | 'assistant',
        content: m.content,
      })),
    ];

    const completion = await this.openai.chat.completions.create({
      model: request.model || this.defaultModel,
      messages,
      temperature: request.temperature ?? 0.4,
      max_tokens: request.maxTokens ?? 4096,
    });

    const choice = completion.choices[0];

    return {
      id: completion.id,
      content: choice.message?.content || '',
      model: completion.model,
      usage: completion.usage
        ? {
            promptTokens: completion.usage.prompt_tokens,
            completionTokens: completion.usage.completion_tokens,
            totalTokens: completion.usage.total_tokens,
          }
        : undefined,
      finishReason: choice.finish_reason || 'stop',
    };
  }

  // ----------------------------------------------------------
  // Streaming chat completion (callback-based for Express compatibility)
  // ----------------------------------------------------------
  async chatStream(
    request: CopilotChatRequest,
    onChunk: (chunk: CopilotStreamChunk) => void,
  ): Promise<void> {
    this.ensureInit();

    const messages: OpenAI.ChatCompletionMessageParam[] = [
      { role: 'system', content: this.buildSystemPrompt(request.projectContext, undefined, request.uiLanguage, request.messages) },
      ...request.messages.map((m) => ({
        role: m.role as 'system' | 'user' | 'assistant',
        content: m.content,
      })),
    ];

    console.log('[chatStream] Starting with model:', this.defaultModel, 'messages:', messages.length);

    try {
      const stream = await this.openai.chat.completions.create({
        model: request.model || this.defaultModel,
        messages,
        temperature: request.temperature ?? 0.4,
        max_tokens: request.maxTokens ?? 4096,
        stream: true,
      });

      console.log('[chatStream] OpenAI stream created, type:', typeof stream, 'Symbol.asyncIterator:', Symbol.asyncIterator in Object(stream));

      for await (const chunk of stream) {
        const delta = chunk.choices?.[0]?.delta;
        const finishReason = chunk.choices?.[0]?.finish_reason;

        if (delta?.content) {
          console.log('[chatStream] content chunk:', delta.content.substring(0, 50));
          onChunk({ type: 'content' as const, content: delta.content });
        }

        if (finishReason) {
          console.log('[chatStream] finish:', finishReason);
          onChunk({ type: 'done' as const, finishReason });
        }
      }

      console.log('[chatStream] Stream complete');
    } catch (error: any) {
      console.error('[chatStream] ERROR:', error.message, error.stack?.substring(0, 300));
      onChunk({ type: 'error' as const, error: error.message || 'Unknown Copilot error' });
    }
  }

  // ----------------------------------------------------------
  // Code generation helper
  // ----------------------------------------------------------
  async generateCode(params: {
    prompt: string;
    language?: string;
    projectContext?: CopilotChatRequest['projectContext'];
  }): Promise<string> {
    const codePrompt = params.language
      ? `G√©n√®re du code ${params.language} pour: ${params.prompt}`
      : `G√©n√®re le code pour: ${params.prompt}`;

    const response = await this.chat({
      messages: [{ role: 'user', content: codePrompt }],
      projectContext: params.projectContext,
      temperature: 0.2,
    });

    return response.content;
  }

  // ----------------------------------------------------------
  // Code review / explanation helper
  // ----------------------------------------------------------
  async reviewCode(params: {
    code: string;
    language?: string;
    action?: 'review' | 'explain' | 'refactor' | 'test';
  }): Promise<string> {
    const actions: Record<string, string> = {
      review: 'Fais une revue de code d√©taill√©e et sugg√®re des am√©liorations',
      explain: 'Explique ce code de mani√®re claire et d√©taill√©e',
      refactor: 'Refactorise ce code pour le rendre plus propre et performant',
      test: 'G√©n√®re des tests unitaires complets pour ce code',
    };

    const action = actions[params.action || 'review'];
    const lang = params.language ? ` (${params.language})` : '';

    const response = await this.chat({
      messages: [
        {
          role: 'user',
          content: `${action} pour le code suivant${lang}:\n\n\`\`\`\n${params.code}\n\`\`\``,
        },
      ],
      temperature: 0.3,
    });

    return response.content;
  }

  // ----------------------------------------------------------
  // GitHub repository helpers (via Octokit)
  // ----------------------------------------------------------
  async getRepoInfo(owner: string, repo: string) {
    this.ensureInit();
    const { data } = await this.octokit.repos.get({ owner, repo });
    return {
      name: data.name,
      fullName: data.full_name,
      description: data.description,
      language: data.language,
      defaultBranch: data.default_branch,
      stars: data.stargazers_count,
      url: data.html_url,
    };
  }

  async getRepoTree(owner: string, repo: string, branch?: string) {
    this.ensureInit();
    const ref = branch || 'main';
    const { data } = await this.octokit.git.getTree({
      owner,
      repo,
      tree_sha: ref,
      recursive: 'true',
    });
    return data.tree
      .filter((item) => item.type === 'blob')
      .map((item) => item.path);
  }

  async getFileContent(owner: string, repo: string, path: string) {
    this.ensureInit();
    const { data } = await this.octokit.repos.getContent({ owner, repo, path });
    if ('content' in data) {
      return Buffer.from(data.content, 'base64').toString('utf-8');
    }
    return null;
  }

  // ----------------------------------------------------------
  // GitHub Copilot availability check
  // ----------------------------------------------------------
  async checkAvailability(): Promise<{
    available: boolean;
    model: string;
    error?: string;
  }> {
    try {
      this.ensureInit();
      const response = await this.chat({
        messages: [{ role: 'user', content: 'ping' }],
        maxTokens: 10,
      });
      return { available: true, model: response.model };
    } catch (error: any) {
      return {
        available: false,
        model: this.defaultModel,
        error: error.message,
      };
    }
  }
}

// Singleton
export const copilotService = new CopilotService();
